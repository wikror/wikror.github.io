<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/">
	<channel>
		<title>üêô</title>
		<description>A personal website</description>
		<link></link>
		<atom:link href="/rss-feed.xml" rel="self" type="application/rss+xml" />
		
			<item>
				<title>CogSci 2021 - additional materials</title>
				
				
					<description>&lt;p&gt;Here you can find link to updated version of the poster:&lt;/p&gt;

&lt;p&gt;[link]&lt;/p&gt;

&lt;p&gt;and some additional results:&lt;/p&gt;

&lt;p&gt;[link]&lt;/p&gt;
</description>
				
				<pubDate>Tue, 22 Jun 2021 00:00:00 +0200</pubDate>
				<link>wiktor.rorot.pl/blog/CogSci2021.html</link>
				<guid isPermaLink="true">wiktor.rorot.pl/blog/CogSci2021.html</guid>
			</item>
		
			<item>
				<title>SPP 2021 - additional materials</title>
				
				
					<description>&lt;p&gt;Here you can find link to the poster:&lt;/p&gt;

&lt;object data=&quot;https://wiktor.rorot.pl/files/rorot-modeling-spatial-purport.pdf&quot; type=&quot;application/pdf&quot; width=&quot;100%&quot; height=&quot;750px&quot;&gt;
    &lt;embed src=&quot;https://wiktor.rorot.pl/files/rorot-modeling-spatial-purport.pdf&quot; type=&quot;application/pdf&quot; /&gt;
        &lt;p&gt;This browser does not support PDFs. Please download the PDF to view it: &lt;a href=&quot;https://wiktor.rorot.pl/files/rorot-modeling-spatial-purport.pdf&quot; target=&quot;_blank&quot;&gt;Download PDF&lt;/a&gt;.&lt;/p&gt;
    &amp;lt;/embed&amp;gt;
&lt;/object&gt;

&lt;p&gt;&lt;a href=&quot;https://wiktor.rorot.pl/files/rorot-modeling-spatial-purport.pdf&quot; target=&quot;_blank&quot;&gt;PDF&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Readable size references:&lt;/p&gt;

&lt;p&gt;Filimon, F. (2015). Are All Spatial Reference Frames Egocentric? https://doi.org/10.3389/fnhum.2015.00648&lt;/p&gt;

&lt;p&gt;Grush, R. (2004). The emulation theory of representation.&lt;/p&gt;

&lt;p&gt;Grush, R. (2007). Skill theory v2.0. https://doi.org/10.1007/s11229-007-9236-z&lt;/p&gt;

&lt;p&gt;Hohwy, J. (2020). New directions in predictive processing. https://doi.org/10.1111/mila.12281&lt;/p&gt;

&lt;p&gt;Laflaqui√®re, A., &amp;amp; Garcia Ortiz, M. (2019). Unsupervised emergence of egocentric spatial structure from sensorimotor prediction.
https://arxiv.org/abs/1906.01401&lt;/p&gt;

&lt;p&gt;Moser, E. I., Kropff, E., &amp;amp; Moser, M.-B. (2008). Place Cells, Grid Cells, and the Brain‚Äôs Spatial Representation System. https://doi.org/10.1146/annurev.neuro.31.061307.090723&lt;/p&gt;

&lt;p&gt;Pouget, A., Deneve, S., &amp;amp; Duhamel, J.-R. (2002). A computational perspective on the neural basis of multisensory spatial representations. https://doi.org/10.1038/nrn914&lt;/p&gt;

&lt;p&gt;Rorot, W. (2020). Explaining ‚Äúspatial purport of perception‚Äù. https://doi.org/10.1007/s11229-020-02678-0&lt;/p&gt;

&lt;p&gt;Wydmuch, M., Kempka, M., &amp;amp; Ja≈õkowski, W. (2018). ViZDoom competitions: Playing doom from pixels. https://arxiv.org/abs/1809.03470&lt;/p&gt;
</description>
				
				<pubDate>Tue, 15 Jun 2021 00:00:00 +0200</pubDate>
				<link>wiktor.rorot.pl/blog/SPP-2021.html</link>
				<guid isPermaLink="true">wiktor.rorot.pl/blog/SPP-2021.html</guid>
			</item>
		
			<item>
				<title>Explaining 'spatial purport of perception': a predictive processing approach</title>
				
				
					<description>&lt;p&gt;Last week my first paper (!) finally came out in Synthese, you can read it &lt;a href=&quot;https://dx.doi.org/10.1007/s11229-020-02678-0&quot;&gt;here&lt;/a&gt;. The paper synthesizes the initial theoretical research of my project on &lt;a href=&quot;wiktor.rorot.pl/projects/individuality.html&quot;&gt;space perception&lt;/a&gt;, focusing on phenomenological aspects that Rick Grush termed ‚Äúspatial purport‚Äù of perceptual experience (&lt;a href=&quot;https://doi.org/10.1007/s11229-007-9236-z&quot;&gt;Grush 2007&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;Space perception has been widely studied in the context of allocentric frame of reference (&lt;a href=&quot;https://doi.org/10.1146/annurev.neuro.31.061307.090723&quot;&gt;think O‚ÄôKeefe, Moser &amp;amp; Moser, place cells, hippocampus&lt;/a&gt;), however egocentric space perception differs significantly in that it is multimodal, closely tied to action, doesn‚Äôt have topographic structure, and ties closely with phenomenal experience of space. Grush offered a high-level model of spatial purport, however this model: a) was never explicitly tested and b) discards a significant part of spatial purport - experience of object-motions (motions induced by sources external to the perceiving subject). In the paper, I analyze the concept of ‚Äúspatial purport‚Äù that Grush left largely underspecified, and show how basic aspect of experience of the world it is (and how it can be usefully operationalized for the purpose of future studies). Then I proceed to use insights from predictive processing to offer a novel extension of Grush‚Äôs skill theory, which takes my criticism (most significantly the issue of object-motions) into account. The model is a high-level proposal, but spelled out in formal terms which should enable its computational and empirical examination. My main project now is to develop simulations to compare the operation of Grush‚Äôs ST2.0 and the PHiST, and I will be posting here once there is some progress and results.&lt;/p&gt;
</description>
				
				<pubDate>Tue, 09 Jun 2020 00:00:00 +0200</pubDate>
				<link>wiktor.rorot.pl/blog/Explaining-spatial-purport.html</link>
				<guid isPermaLink="true">wiktor.rorot.pl/blog/Explaining-spatial-purport.html</guid>
			</item>
		
			<item>
				<title>Test</title>
				
				
					<description>&lt;p&gt;Test MathJax:
When \(a \ne 0\), there are two solutions to \(ax^2 + bx + c = 0\) and they are
\(x = {-b \pm \sqrt{b^2-4ac} \over 2a}.\)&lt;/p&gt;
</description>
				
				<pubDate>Tue, 28 Apr 2020 00:00:00 +0200</pubDate>
				<link>wiktor.rorot.pl/blog/test.html</link>
				<guid isPermaLink="true">wiktor.rorot.pl/blog/test.html</guid>
			</item>
		
	</channel>
</rss>
